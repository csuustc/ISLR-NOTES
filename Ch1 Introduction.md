# Ch1 Introduction

### Supervised learning

* Accurately predict unseen test cases.
* understand which inputs affect the outcome, and how.
* Assess the quality of our predictions and inferences.

### Unsupervised learning

* No outcome variable, just a set of predictors (features) measured on a set of samples.
* objective is more fuzzy — find groups of samples that behave similarly, find features that behave similarly, find linear combinations of features with the most variation.
* difficult to know how well your are doing.

### History
* 19th century, Legendre & Gauss, *method of least squares*
* 1936, Fisher *Linear discriminant analysis*; 1940, *logistic regression*; 1970s, Nelder & Wedderburn *generalized linear models*
* 1980s, *classification & regression trees*

### Why not Black Boxes?
No single approach will perform well in all possible applications. Without understanding all of the cogs inside the box, or the interaction between those cogs, it is impossible to select the best box. Hence, we have attempted to carefully describe the model, intuition, assumptions, and trade-offs behind each of the methods that we consider.

### Machine learning
* Machine learning arose as a subfield of Artificial Intelligence.
* Statistical learning arose as a subfield of Statistics. 
* There is much overlap — both fields focus on supervised and unsupervised problems:
  * Machine learning has a greater emphasis on large scale applications and prediction accuracy.
  * Statistical learning emphasizes models and their interpretability, and precision and uncertainty.
